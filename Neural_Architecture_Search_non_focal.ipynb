{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6ed45bf-37f1-4189-b696-5707062d2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b28b366-738f-41db-8047-3de5ca425f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2db926-014f-4233-8ea8-18de6828d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetinaTransform(image):\n",
    "    # Bringing image to 0-1 range, #ATTENTION: CHECK IF ALL IMAGES min max is 0 and 255\n",
    "    image = image / 255\n",
    "    \n",
    "    \n",
    "    image = resize(image, (64,64),anti_aliasing=False) # resizing image because original does not fit in memory.\n",
    "    \n",
    "    \n",
    "    # Bringing data to CHW format\n",
    "    # N is a batch size, C denotes a number of channels, \n",
    "    # H is a height of input planes in pixels, and W is width in pixels.\n",
    "    image = image.transpose([2,0,1])\n",
    "    \n",
    "    #Fixing dtype to avoid runtime error and save memory\n",
    "    image = torch.tensor(image ,dtype=torch.float32)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a6109b-def2-433d-ba14-ac74117cdee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 640/640 [01:16<00:00,  8.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Load dataset into memory\n",
    "# cuda_image_array = []\n",
    "# data_folder = \"Evaluation_Set/Validation\"\n",
    "# label_path = \"Evaluation_Set/RFMiD_Validation_Labels.csv\"\n",
    "# label_frame = pd.read_csv(label_path)\n",
    "# local_transform = RetinaTransform\n",
    "\n",
    "# for image_name in tqdm(glob(data_folder+\"/*\")):\n",
    "#     image = io.imread(image_name)\n",
    "\n",
    "#     label_frame_index = int(image_name.split(\"/\")[-1].split(\".\")[0])\n",
    "#     label = label_frame[label_frame[\"ID\"]==label_frame_index][\"Disease_Risk\"].values[0]\n",
    "\n",
    "#     image = local_transform(image)\n",
    "#     label =  torch.tensor(label ,dtype=torch.float32)\n",
    "\n",
    "#     cuda_image_array.append((image,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a29b310-0f04-4801-95bc-52611702d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CicikNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CicikNet, self).__init__()\n",
    "\n",
    "        \n",
    "        self.lrelu = nn.LeakyReLU(0.1)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1,padding=1)\n",
    "\n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(64*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.dropout = nn.Dropout(p=0.9)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = torch.flatten(self.conv1(x),1)\n",
    "        x = torch.cat([x1],dim=1)\n",
    "        # x = self.dropout(x)\n",
    "        \n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        output = torch.sigmoid(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c33fea2d-5297-43bd-956d-7d31e9485df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_indices, transform=None):\n",
    "        \n",
    "        self.data = [cuda_image_array[idx] for idx in data_indices]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cc2e61f9-4ec4-4113-a8c8-308091e581ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_grad_flow(named_parameters):\n",
    "#     ave_grads = []\n",
    "#     layers = []\n",
    "#     for n, p in named_parameters:\n",
    "#         if(p.requires_grad) and (\"bias\" not in n):\n",
    "#             layers.append(n)\n",
    "#             ave_grads.append(p.grad.abs().mean())\n",
    "#     plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "#     plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "#     plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "#     plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "#     plt.xlabel(\"Layers\")\n",
    "#     plt.ylabel(\"average gradient\")\n",
    "#     plt.title(\"Gradient flow\")\n",
    "#     plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "57f4c0ac-42c6-4f3c-97be-ae84c0f07e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_loop(net,criterion,train_dataloader):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    \n",
    "    for idx, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs\n",
    "        # print(i,data)\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        # labels = labels.to(device)\n",
    "        labels = torch.ones(1).to(device)\n",
    "        \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs.flatten(), labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=10)\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        predictions.append(outputs.flatten())\n",
    "        ground_truth.append(labels.flatten())\n",
    "        \n",
    "    # net.to('cpu')\n",
    "    # plot_grad_flow(net.named_parameters())\n",
    "    # plt.show()\n",
    "    # net.to(device)\n",
    "    \n",
    "    predictions=torch.cat(predictions)\n",
    "    ground_truth = torch.cat(ground_truth)\n",
    "    print(predictions,ground_truth)\n",
    "    healthy_f1 = 0\n",
    "    # healthy_f1 = f1_score((predictions>0.5).float().cpu(),ground_truth.cpu(),pos_label=0)\n",
    "    rocauc = bauc(predictions,ground_truth)\n",
    "    print('[%d, %5d] loss: %.3f, ROC: %.3f, F1_healthy: %.3f\\n' % (epoch + 1, idx + 1, running_loss, rocauc, healthy_f1))\n",
    "\n",
    "    return running_loss, rocauc, healthy_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "288e3233-6d63-4604-9571-1faca330a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test_loop(net, criterion, test_dataloader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        test_predictions = []\n",
    "        test_ground_truth = []\n",
    "        \n",
    "        for idx, data in enumerate(test_dataloader, 0):\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs.flatten(), labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            test_predictions.append(outputs.flatten())\n",
    "            test_ground_truth.append(labels.flatten())\n",
    "\n",
    "        \n",
    "        \n",
    "        test_predictions=torch.cat(test_predictions)\n",
    "        test_ground_truth = torch.cat(test_ground_truth)\n",
    "\n",
    "        healthy_f1 = 0\n",
    "        # healthy_f1 = f1_score((test_predictions>0.5).float().cpu(),test_ground_truth.cpu(),pos_label=0)\n",
    "        rocauc = bauc(test_predictions,test_ground_truth)\n",
    "        print('[%d, %5d] Validation loss: %.3f, ROC: %.3f, F1_healthy: %.3f \\n' % (epoch + 1, idx + 1, running_loss, rocauc, healthy_f1))\n",
    "        \n",
    "        return running_loss, rocauc,healthy_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c3d576f-244e-49d0-b380-4ff9aaad5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "criterion = nn.BCELoss()\n",
    "bauc = BinaryAUROC(thresholds=None)\n",
    "writer = SummaryWriter('experiments/crossval_test_experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1790cbcb-7706-4aae-8091-ff93a1c28bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   320] loss: 189.643, ROC: 0.496, F1_healthy: 0.000\n",
      "\n",
      "[1,   320] Validation loss: 145.476, ROC: 0.649, F1_healthy: 0.000 \n",
      "\n",
      "[2,   320] loss: 180.201, ROC: 0.538, F1_healthy: 0.000\n",
      "\n",
      "[2,   320] Validation loss: 149.657, ROC: 0.634, F1_healthy: 0.000 \n",
      "\n",
      "[3,   320] loss: 174.653, ROC: 0.586, F1_healthy: 0.000\n",
      "\n",
      "[3,   320] Validation loss: 143.008, ROC: 0.677, F1_healthy: 0.000 \n",
      "\n",
      "[4,   320] loss: 174.087, ROC: 0.586, F1_healthy: 0.000\n",
      "\n",
      "[4,   320] Validation loss: 144.014, ROC: 0.660, F1_healthy: 0.000 \n",
      "\n",
      "[5,   320] loss: 169.334, ROC: 0.637, F1_healthy: 0.000\n",
      "\n",
      "[5,   320] Validation loss: 139.698, ROC: 0.693, F1_healthy: 0.000 \n",
      "\n",
      "[6,   320] loss: 166.920, ROC: 0.652, F1_healthy: 0.000\n",
      "\n",
      "[6,   320] Validation loss: 139.000, ROC: 0.691, F1_healthy: 0.000 \n",
      "\n",
      "[7,   320] loss: 164.443, ROC: 0.664, F1_healthy: 0.000\n",
      "\n",
      "[7,   320] Validation loss: 137.574, ROC: 0.694, F1_healthy: 0.000 \n",
      "\n",
      "[8,   320] loss: 162.247, ROC: 0.677, F1_healthy: 0.000\n",
      "\n",
      "[8,   320] Validation loss: 136.713, ROC: 0.695, F1_healthy: 0.000 \n",
      "\n",
      "[9,   320] loss: 160.540, ROC: 0.686, F1_healthy: 0.000\n",
      "\n",
      "[9,   320] Validation loss: 134.499, ROC: 0.710, F1_healthy: 0.000 \n",
      "\n",
      "[10,   320] loss: 157.309, ROC: 0.702, F1_healthy: 0.000\n",
      "\n",
      "[10,   320] Validation loss: 132.984, ROC: 0.715, F1_healthy: 0.000 \n",
      "\n",
      "[11,   320] loss: 155.108, ROC: 0.731, F1_healthy: 0.000\n",
      "\n",
      "[11,   320] Validation loss: 130.764, ROC: 0.732, F1_healthy: 0.000 \n",
      "\n",
      "[12,   320] loss: 149.854, ROC: 0.759, F1_healthy: 0.000\n",
      "\n",
      "[12,   320] Validation loss: 127.690, ROC: 0.757, F1_healthy: 0.000 \n",
      "\n",
      "[13,   320] loss: 144.919, ROC: 0.786, F1_healthy: 0.000\n",
      "\n",
      "[13,   320] Validation loss: 125.464, ROC: 0.770, F1_healthy: 0.000 \n",
      "\n",
      "[14,   320] loss: 139.851, ROC: 0.804, F1_healthy: 0.000\n",
      "\n",
      "[14,   320] Validation loss: 122.853, ROC: 0.785, F1_healthy: 0.000 \n",
      "\n",
      "[15,   320] loss: 134.004, ROC: 0.825, F1_healthy: 0.000\n",
      "\n",
      "[15,   320] Validation loss: 122.801, ROC: 0.789, F1_healthy: 0.000 \n",
      "\n",
      "[16,   320] loss: 131.223, ROC: 0.830, F1_healthy: 0.000\n",
      "\n",
      "[16,   320] Validation loss: 120.467, ROC: 0.806, F1_healthy: 0.000 \n",
      "\n",
      "[17,   320] loss: 126.160, ROC: 0.846, F1_healthy: 0.000\n",
      "\n",
      "[17,   320] Validation loss: 120.487, ROC: 0.811, F1_healthy: 0.000 \n",
      "\n",
      "[18,   320] loss: 120.545, ROC: 0.858, F1_healthy: 0.000\n",
      "\n",
      "[18,   320] Validation loss: 120.066, ROC: 0.817, F1_healthy: 0.000 \n",
      "\n",
      "[19,   320] loss: 113.843, ROC: 0.877, F1_healthy: 0.000\n",
      "\n",
      "[19,   320] Validation loss: 121.085, ROC: 0.821, F1_healthy: 0.000 \n",
      "\n",
      "[20,   320] loss: 108.098, ROC: 0.891, F1_healthy: 0.000\n",
      "\n",
      "[20,   320] Validation loss: 122.656, ROC: 0.827, F1_healthy: 0.000 \n",
      "\n",
      "[21,   320] loss: 106.634, ROC: 0.895, F1_healthy: 0.000\n",
      "\n",
      "[21,   320] Validation loss: 125.301, ROC: 0.819, F1_healthy: 0.000 \n",
      "\n",
      "[22,   320] loss: 97.292, ROC: 0.915, F1_healthy: 0.000\n",
      "\n",
      "[22,   320] Validation loss: 125.052, ROC: 0.832, F1_healthy: 0.000 \n",
      "\n",
      "[23,   320] loss: 93.764, ROC: 0.920, F1_healthy: 0.000\n",
      "\n",
      "[23,   320] Validation loss: 135.115, ROC: 0.835, F1_healthy: 0.000 \n",
      "\n",
      "[24,   320] loss: 85.792, ROC: 0.934, F1_healthy: 0.000\n",
      "\n",
      "[24,   320] Validation loss: 143.480, ROC: 0.821, F1_healthy: 0.000 \n",
      "\n",
      "[25,   320] loss: 87.714, ROC: 0.928, F1_healthy: 0.000\n",
      "\n",
      "[25,   320] Validation loss: 130.632, ROC: 0.809, F1_healthy: 0.000 \n",
      "\n",
      "[26,   320] loss: 88.380, ROC: 0.924, F1_healthy: 0.000\n",
      "\n",
      "[26,   320] Validation loss: 154.364, ROC: 0.821, F1_healthy: 0.000 \n",
      "\n",
      "[27,   320] loss: 68.577, ROC: 0.952, F1_healthy: 0.000\n",
      "\n",
      "[27,   320] Validation loss: 148.692, ROC: 0.837, F1_healthy: 0.000 \n",
      "\n",
      "[28,   320] loss: 59.082, ROC: 0.962, F1_healthy: 0.000\n",
      "\n",
      "[28,   320] Validation loss: 153.839, ROC: 0.829, F1_healthy: 0.000 \n",
      "\n",
      "[29,   320] loss: 53.267, ROC: 0.969, F1_healthy: 0.000\n",
      "\n",
      "[29,   320] Validation loss: 168.085, ROC: 0.827, F1_healthy: 0.000 \n",
      "\n",
      "[30,   320] loss: 50.111, ROC: 0.970, F1_healthy: 0.000\n",
      "\n",
      "[30,   320] Validation loss: 171.802, ROC: 0.834, F1_healthy: 0.000 \n",
      "\n",
      "[31,   320] loss: 60.145, ROC: 0.962, F1_healthy: 0.000\n",
      "\n",
      "[31,   320] Validation loss: 159.581, ROC: 0.828, F1_healthy: 0.000 \n",
      "\n",
      "[32,   320] loss: 69.926, ROC: 0.949, F1_healthy: 0.000\n",
      "\n",
      "[32,   320] Validation loss: 240.725, ROC: 0.808, F1_healthy: 0.000 \n",
      "\n",
      "[33,   320] loss: 7605.575, ROC: 0.496, F1_healthy: 0.000\n",
      "\n",
      "[33,   320] Validation loss: 5800.000, ROC: 0.498, F1_healthy: 0.000 \n",
      "\n",
      "[34,   320] loss: 7600.000, ROC: 0.500, F1_healthy: 0.000\n",
      "\n",
      "[34,   320] Validation loss: 5800.000, ROC: 0.498, F1_healthy: 0.000 \n",
      "\n",
      "[35,   320] loss: 7600.000, ROC: 0.500, F1_healthy: 0.000\n",
      "\n",
      "[35,   320] Validation loss: 5800.000, ROC: 0.498, F1_healthy: 0.000 \n",
      "\n",
      "[36,   320] loss: 7600.000, ROC: 0.500, F1_healthy: 0.000\n",
      "\n",
      "[36,   320] Validation loss: 5800.000, ROC: 0.498, F1_healthy: 0.000 \n",
      "\n",
      "[37,   320] loss: 7600.000, ROC: 0.500, F1_healthy: 0.000\n",
      "\n",
      "[37,   320] Validation loss: 5800.000, ROC: 0.498, F1_healthy: 0.000 \n",
      "\n",
      "[38,   320] loss: 7600.000, ROC: 0.500, F1_healthy: 0.000\n",
      "\n",
      "[38,   320] Validation loss: 5800.000, ROC: 0.498, F1_healthy: 0.000 \n",
      "\n",
      "[39,   320] loss: 7600.000, ROC: 0.500, F1_healthy: 0.000\n",
      "\n",
      "[39,   320] Validation loss: 5800.000, ROC: 0.498, F1_healthy: 0.000 \n",
      "\n",
      "[40,   320] loss: 7600.000, ROC: 0.500, F1_healthy: 0.000\n",
      "\n",
      "[40,   320] Validation loss: 5800.000, ROC: 0.498, F1_healthy: 0.000 \n",
      "\n",
      "[41,   320] loss: 7600.000, ROC: 0.500, F1_healthy: 0.000\n",
      "\n",
      "[41,   320] Validation loss: 5800.000, ROC: 0.498, F1_healthy: 0.000 \n",
      "\n",
      "[42,   320] loss: 7600.000, ROC: 0.500, F1_healthy: 0.000\n",
      "\n",
      "[42,   320] Validation loss: 5800.000, ROC: 0.498, F1_healthy: 0.000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:20, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=2)\n",
    "\n",
    "fold_rocauc = []\n",
    "fold_f1healthy = []\n",
    "fold_loss = []\n",
    "for idx, (train_index, test_index) in tqdm(enumerate(kf.split(cuda_image_array))):\n",
    "    train_dataset = RetinaDataset(data_indices=train_index)\n",
    "    test_dataset = RetinaDataset(data_indices=test_index)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    ciciknet = CicikNet().to(device)\n",
    "    optimizer = optim.SGD(ciciknet.parameters(), lr=0.001, momentum = 0.9) # Understand why ADAM does not work with batchsize = 1\n",
    "    # optimizer = optim.Adam(ciciknet.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "        loss_train, rocauc_train, f1healthy_train= model_train_loop(ciciknet, criterion,train_dataloader)\n",
    "        loss_test, rocauc_test, f1healthy_test = model_test_loop(ciciknet, criterion,test_dataloader)\n",
    "        \n",
    "        writer.add_scalars('training/val rocauc', {\"train_rocauc\":rocauc_train,\"validation_rocauc\":rocauc_test}, epoch +1)\n",
    "        writer.add_scalars('training/val healthy_f1', {\"f1healthy_train\":f1healthy_train,\"f1healthy_test\":f1healthy_test}, epoch +1)\n",
    "        writer.add_scalars('training/val loss', {\"loss_train\":loss_train,\"loss_test\":loss_test}, epoch +1)\n",
    "        \n",
    "        \n",
    "    loss_, rocauc, f1healthy = model_test_loop(ciciknet, criterion, test_dataloader)\n",
    "    \n",
    "    fold_rocauc.append(rocauc)\n",
    "    fold_f1healthy.append(f1healthy)\n",
    "    fold_loss.append(loss_)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16a75e-5610-444e-9483-45d80e089dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EPOCHS = 100\n",
    "# criterion = nn.BCELoss()\n",
    "# bauc = BinaryAUROC(thresholds=None)\n",
    "\n",
    "# kf = KFold(n_splits=5)\n",
    "\n",
    "# fold_rocauc = []\n",
    "# fold_f1healthy = []\n",
    "\n",
    "# for idx, (train_index, test_index) in tqdm(enumerate(kf.split(cuda_image_array))):\n",
    "#     train_dataset = RetinaDataset(data_indices=train_index)\n",
    "#     test_dataset = RetinaDataset(data_indices=test_index)\n",
    "    \n",
    "#     train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
    "#     test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
    "    \n",
    "#     ciciknet = CicikNet().to(device)\n",
    "#     optimizer = optim.SGD(ciciknet.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "#     for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "#         model_train_loop(ciciknet,train_dataloader)\n",
    "    \n",
    "#     rocauc, f1healthy = model_test_loop(ciciknet,test_dataloader)\n",
    "    \n",
    "#     fold_rocauc.append(rocauc)\n",
    "#     fold_f1healthy.append(f1healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "80e73972-9af7-4b17-b547-a1e196198ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.8736, device='cuda:0'), tensor(0.8384, device='cuda:0'), tensor(0.7858, device='cuda:0'), tensor(0.8760, device='cuda:0'), tensor(0.8380, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "print(fold_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "c3f56415-ed3f-4830-9b4e-646109647db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6885245901639345, 0.5, 0.4583333333333333, 0.5818181818181819, 0.5964912280701754]\n"
     ]
    }
   ],
   "source": [
    "print(fold_f1healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfbb38-67a7-4cd3-bc5d-46ea9ac4b1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
