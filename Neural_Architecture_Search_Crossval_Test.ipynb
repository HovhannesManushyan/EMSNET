{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ed45bf-37f1-4189-b696-5707062d2ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b28b366-738f-41db-8047-3de5ca425f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2db926-014f-4233-8ea8-18de6828d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetinaTransform(image):\n",
    "    # Bringing image to 0-1 range, #ATTENTION: CHECK IF ALL IMAGES min max is 0 and 255\n",
    "    image = image / 255\n",
    "    \n",
    "    \n",
    "    image = resize(image, (64,64),anti_aliasing=False) # resizing image because original does not fit in memory.\n",
    "    \n",
    "    \n",
    "    # Bringing data to CHW format\n",
    "    # N is a batch size, C denotes a number of channels, \n",
    "    # H is a height of input planes in pixels, and W is width in pixels.\n",
    "    image = image.transpose([2,0,1])\n",
    "    \n",
    "    #Fixing dtype to avoid runtime error and save memory\n",
    "    image = torch.tensor(image ,dtype=torch.float32)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a6109b-def2-433d-ba14-ac74117cdee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 640/640 [01:18<00:00,  8.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Load dataset into memory\n",
    "# cuda_image_array = []\n",
    "# data_folder = \"Evaluation_Set/Validation\"\n",
    "# label_path = \"Evaluation_Set/RFMiD_Validation_Labels.csv\"\n",
    "# label_frame = pd.read_csv(label_path)\n",
    "# local_transform = RetinaTransform\n",
    "\n",
    "# for image_name in tqdm(glob(data_folder+\"/*\")):\n",
    "#     image = io.imread(image_name)\n",
    "\n",
    "#     label_frame_index = int(image_name.split(\"/\")[-1].split(\".\")[0])\n",
    "#     label = label_frame[label_frame[\"ID\"]==label_frame_index][\"Disease_Risk\"].values[0]\n",
    "\n",
    "#     image = local_transform(image)\n",
    "#     label =  torch.tensor(label ,dtype=torch.float32)\n",
    "\n",
    "#     cuda_image_array.append((image,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a29b310-0f04-4801-95bc-52611702d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CicikNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CicikNet, self).__init__()\n",
    "\n",
    "        \n",
    "        self.lrelu = nn.LeakyReLU(0.1)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1,padding=1)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5, stride=1,padding=2)\n",
    "        # self.conv3 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=10, stride=1,padding=5)\n",
    "\n",
    "\n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(64*64, 640)\n",
    "        # Second fully connected layer that outputs our 10 labels\n",
    "        self.fc2 = nn.Linear(640, 2)\n",
    "        \n",
    "        self.dpl = nn.Dropout(p=0.85)\n",
    "        \n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = torch.flatten(self.conv1(x),1) \n",
    "        x = torch.cat([x1],dim=1)\n",
    "        \n",
    "        x = self.dpl(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.lrelu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        output = self.sm(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c33fea2d-5297-43bd-956d-7d31e9485df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_indices, transform=None):\n",
    "        \n",
    "        self.data = [cuda_image_array[idx] for idx in data_indices]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc2e61f9-4ec4-4113-a8c8-308091e581ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_grad_flow(named_parameters):\n",
    "#     ave_grads = []\n",
    "#     layers = []\n",
    "#     for n, p in named_parameters:\n",
    "#         if(p.requires_grad) and (\"bias\" not in n):\n",
    "#             layers.append(n)\n",
    "#             ave_grads.append(p.grad.abs().mean())\n",
    "#     plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "#     plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "#     plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "#     plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "#     plt.xlabel(\"Layers\")\n",
    "#     plt.ylabel(\"average gradient\")\n",
    "#     plt.title(\"Gradient flow\")\n",
    "#     plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a35b0a1b-3f05-49e6-96db-7b10ad01c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x, y = torch.randn(10, 2), (torch.rand(10) > .5).long()\n",
    "# loss = focal_loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebe18fd1-4035-4046-93a3-9a91d06d7ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/john/.cache/torch/hub/adeelh_pytorch-multi-class-focal-loss_master\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "# bceloss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5]).to(device))\n",
    "# celoss = nn.CrossEntropyLoss(weight=torch.tensor([0.2,0.8]).to(device))\n",
    "\n",
    "focal_loss = torch.hub.load(\n",
    "'adeelh/pytorch-multi-class-focal-loss',\n",
    "model='FocalLoss',\n",
    "alpha=torch.tensor([0.8, 0.2]).to(device),\n",
    "gamma=2,\n",
    "reduction='mean',\n",
    "force_reload=False\n",
    ")\n",
    "\n",
    "bauc = BinaryAUROC(thresholds=None)\n",
    "\n",
    "writer = SummaryWriter('experiments/crossval_test_experiment')\n",
    "# weight_decay =1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0328705-805f-44d7-997a-a1b7b76ed1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# focal_loss(torch.tensor([[0.0,1.0]]).to(device),torch.tensor([0]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12a8e4a9-7036-4b4c-a568-2e77ebad87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of target with class indices\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "# print(input.shape)\n",
    "# print(input,target)\n",
    "# print(loss(input,target))\n",
    "# output = loss(input, target)\n",
    "# output.backward()\n",
    "# # Example of target with class probabilities\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.randn(3, 5).softmax(dim=1)\n",
    "# output = loss(input, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57f4c0ac-42c6-4f3c-97be-ae84c0f07e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_loop(net,train_dataloader):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    \n",
    "    for idx, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs\n",
    "        # print(i,data)\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "    \n",
    "        # plt.imshow(inputs[0].cpu().numpy().transpose([2,1,0]))\n",
    "        # plt.show()\n",
    "        \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = focal_loss(outputs, labels.long())\n",
    "        \n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=100)  # Clipping to avoid vanishing gradient problem we saw.\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        predictions.append(outputs[:,1].flatten())\n",
    "        ground_truth.append(labels.flatten())\n",
    "        \n",
    "    # net.to('cpu')\n",
    "    # plot_grad_flow(net.named_parameters())\n",
    "    # plt.show()\n",
    "    # net.to(device)\n",
    "    \n",
    "    predictions=torch.cat(predictions)\n",
    "    ground_truth = torch.cat(ground_truth)\n",
    "    \n",
    "    \n",
    "    healthy_f1 = f1_score((predictions>0.5).float().cpu(),ground_truth.cpu(),pos_label=0)\n",
    "    rocauc = bauc(predictions,ground_truth)\n",
    "    \n",
    "    print('[%d, %5d] loss: %.3f, ROC: %.3f, F1_healthy: %.3f\\n' % (epoch + 1, idx + 1, running_loss, rocauc, healthy_f1))\n",
    "    return running_loss, rocauc,healthy_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "288e3233-6d63-4604-9571-1faca330a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test_loop(net, test_dataloader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        test_predictions = []\n",
    "        test_ground_truth = []\n",
    "        \n",
    "        for idx, data in enumerate(test_dataloader, 0):\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = focal_loss(outputs, labels.long())\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            test_predictions.append(outputs[:,1].flatten())\n",
    "            test_ground_truth.append(labels.flatten())\n",
    "\n",
    "        \n",
    "        \n",
    "        test_predictions=torch.cat(test_predictions)\n",
    "        test_ground_truth = torch.cat(test_ground_truth)\n",
    "\n",
    "\n",
    "        healthy_f1 = f1_score((test_predictions>0.5).float().cpu(),test_ground_truth.cpu(),pos_label=0)\n",
    "        rocauc = bauc(test_predictions,test_ground_truth)\n",
    "        \n",
    "        print('[%d, %5d] Validation loss: %.3f, ROC: %.3f, F1_healthy: %.3f \\n' % (epoch + 1, idx + 1, running_loss, rocauc, healthy_f1))\n",
    "        \n",
    "        return running_loss, rocauc,healthy_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "157d7951-8e5c-4f84-a02e-55a7b3b81fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score((predictions>0.5).float().cpu(),ground_truth.cpu(),pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47646ac0-1c6d-496e-abfa-4634d61be3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db187dc5-3287-4bbd-9bb4-d471ad197730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL learns the trivial case of all 1s, which means it has capacity to learn:\n",
    "\n",
    "\n",
    "    \n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdfeafa1-6c5b-4da0-b41b-6466f71f649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor([[1,2],[3,4]])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c16a75e-5610-444e-9483-45d80e089dc3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   320] loss: 19.058, ROC: 0.417, F1_healthy: 0.372\n",
      "\n",
      "[1,   320] Validation loss: 17.222, ROC: 0.534, F1_healthy: 0.309 \n",
      "\n",
      "[2,   320] loss: 18.899, ROC: 0.478, F1_healthy: 0.384\n",
      "\n",
      "[2,   320] Validation loss: 17.175, ROC: 0.639, F1_healthy: 0.308 \n",
      "\n",
      "[3,   320] loss: 18.815, ROC: 0.549, F1_healthy: 0.384\n",
      "\n",
      "[3,   320] Validation loss: 17.189, ROC: 0.642, F1_healthy: 0.307 \n",
      "\n",
      "[4,   320] loss: 18.842, ROC: 0.531, F1_healthy: 0.380\n",
      "\n",
      "[4,   320] Validation loss: 17.219, ROC: 0.620, F1_healthy: 0.307 \n",
      "\n",
      "[5,   320] loss: 18.754, ROC: 0.553, F1_healthy: 0.385\n",
      "\n",
      "[5,   320] Validation loss: 17.196, ROC: 0.633, F1_healthy: 0.307 \n",
      "\n",
      "[6,   320] loss: 18.744, ROC: 0.590, F1_healthy: 0.385\n",
      "\n",
      "[6,   320] Validation loss: 17.155, ROC: 0.622, F1_healthy: 0.309 \n",
      "\n",
      "[7,   320] loss: 18.696, ROC: 0.591, F1_healthy: 0.389\n",
      "\n",
      "[7,   320] Validation loss: 17.159, ROC: 0.630, F1_healthy: 0.308 \n",
      "\n",
      "[8,   320] loss: 18.685, ROC: 0.579, F1_healthy: 0.391\n",
      "\n",
      "[8,   320] Validation loss: 17.092, ROC: 0.645, F1_healthy: 0.306 \n",
      "\n",
      "[9,   320] loss: 18.626, ROC: 0.585, F1_healthy: 0.387\n",
      "\n",
      "[9,   320] Validation loss: 17.037, ROC: 0.645, F1_healthy: 0.310 \n",
      "\n",
      "[10,   320] loss: 18.564, ROC: 0.616, F1_healthy: 0.388\n",
      "\n",
      "[10,   320] Validation loss: 17.027, ROC: 0.648, F1_healthy: 0.311 \n",
      "\n",
      "[11,   320] loss: 18.552, ROC: 0.618, F1_healthy: 0.397\n",
      "\n",
      "[11,   320] Validation loss: 16.935, ROC: 0.670, F1_healthy: 0.312 \n",
      "\n",
      "[12,   320] loss: 18.559, ROC: 0.598, F1_healthy: 0.370\n",
      "\n",
      "[12,   320] Validation loss: 16.932, ROC: 0.624, F1_healthy: 0.308 \n",
      "\n",
      "[13,   320] loss: 18.418, ROC: 0.618, F1_healthy: 0.394\n",
      "\n",
      "[13,   320] Validation loss: 16.868, ROC: 0.658, F1_healthy: 0.319 \n",
      "\n",
      "[14,   320] loss: 18.348, ROC: 0.629, F1_healthy: 0.389\n",
      "\n",
      "[14,   320] Validation loss: 16.784, ROC: 0.666, F1_healthy: 0.317 \n",
      "\n",
      "[15,   320] loss: 18.163, ROC: 0.665, F1_healthy: 0.418\n",
      "\n",
      "[15,   320] Validation loss: 16.796, ROC: 0.636, F1_healthy: 0.314 \n",
      "\n",
      "[16,   320] loss: 18.337, ROC: 0.623, F1_healthy: 0.364\n",
      "\n",
      "[16,   320] Validation loss: 16.678, ROC: 0.643, F1_healthy: 0.325 \n",
      "\n",
      "[17,   320] loss: 18.079, ROC: 0.652, F1_healthy: 0.401\n",
      "\n",
      "[17,   320] Validation loss: 16.540, ROC: 0.682, F1_healthy: 0.338 \n",
      "\n",
      "[18,   320] loss: 18.070, ROC: 0.647, F1_healthy: 0.389\n",
      "\n",
      "[18,   320] Validation loss: 16.621, ROC: 0.622, F1_healthy: 0.323 \n",
      "\n",
      "[19,   320] loss: 17.992, ROC: 0.634, F1_healthy: 0.381\n",
      "\n",
      "[19,   320] Validation loss: 16.495, ROC: 0.647, F1_healthy: 0.331 \n",
      "\n",
      "[20,   320] loss: 18.108, ROC: 0.611, F1_healthy: 0.371\n",
      "\n",
      "[20,   320] Validation loss: 16.255, ROC: 0.686, F1_healthy: 0.349 \n",
      "\n",
      "[21,   320] loss: 17.851, ROC: 0.657, F1_healthy: 0.414\n",
      "\n",
      "[21,   320] Validation loss: 16.191, ROC: 0.692, F1_healthy: 0.366 \n",
      "\n",
      "[22,   320] loss: 17.857, ROC: 0.642, F1_healthy: 0.397\n",
      "\n",
      "[22,   320] Validation loss: 16.152, ROC: 0.681, F1_healthy: 0.362 \n",
      "\n",
      "[23,   320] loss: 17.681, ROC: 0.660, F1_healthy: 0.432\n",
      "\n",
      "[23,   320] Validation loss: 16.149, ROC: 0.682, F1_healthy: 0.358 \n",
      "\n",
      "[24,   320] loss: 17.712, ROC: 0.664, F1_healthy: 0.423\n",
      "\n",
      "[24,   320] Validation loss: 16.218, ROC: 0.671, F1_healthy: 0.351 \n",
      "\n",
      "[25,   320] loss: 17.387, ROC: 0.690, F1_healthy: 0.429\n",
      "\n",
      "[25,   320] Validation loss: 16.259, ROC: 0.655, F1_healthy: 0.351 \n",
      "\n",
      "[26,   320] loss: 17.381, ROC: 0.689, F1_healthy: 0.447\n",
      "\n",
      "[26,   320] Validation loss: 16.228, ROC: 0.675, F1_healthy: 0.385 \n",
      "\n",
      "[27,   320] loss: 17.547, ROC: 0.661, F1_healthy: 0.403\n",
      "\n",
      "[27,   320] Validation loss: 15.899, ROC: 0.712, F1_healthy: 0.413 \n",
      "\n",
      "[28,   320] loss: 17.436, ROC: 0.682, F1_healthy: 0.431\n",
      "\n",
      "[28,   320] Validation loss: 15.880, ROC: 0.680, F1_healthy: 0.383 \n",
      "\n",
      "[29,   320] loss: 17.279, ROC: 0.697, F1_healthy: 0.449\n",
      "\n",
      "[29,   320] Validation loss: 16.139, ROC: 0.657, F1_healthy: 0.359 \n",
      "\n",
      "[30,   320] loss: 17.465, ROC: 0.658, F1_healthy: 0.407\n",
      "\n",
      "[30,   320] Validation loss: 15.737, ROC: 0.716, F1_healthy: 0.398 \n",
      "\n",
      "[31,   320] loss: 17.404, ROC: 0.668, F1_healthy: 0.425\n",
      "\n",
      "[31,   320] Validation loss: 15.699, ROC: 0.703, F1_healthy: 0.370 \n",
      "\n",
      "[32,   320] loss: 17.578, ROC: 0.658, F1_healthy: 0.434\n",
      "\n",
      "[32,   320] Validation loss: 15.695, ROC: 0.726, F1_healthy: 0.406 \n",
      "\n",
      "[33,   320] loss: 17.232, ROC: 0.692, F1_healthy: 0.456\n",
      "\n",
      "[33,   320] Validation loss: 15.924, ROC: 0.684, F1_healthy: 0.353 \n",
      "\n",
      "[34,   320] loss: 17.424, ROC: 0.663, F1_healthy: 0.416\n",
      "\n",
      "[34,   320] Validation loss: 15.960, ROC: 0.682, F1_healthy: 0.426 \n",
      "\n",
      "[35,   320] loss: 17.267, ROC: 0.699, F1_healthy: 0.440\n",
      "\n",
      "[35,   320] Validation loss: 15.930, ROC: 0.691, F1_healthy: 0.372 \n",
      "\n",
      "[36,   320] loss: 17.095, ROC: 0.701, F1_healthy: 0.436\n",
      "\n",
      "[36,   320] Validation loss: 15.761, ROC: 0.695, F1_healthy: 0.392 \n",
      "\n",
      "[37,   320] loss: 17.190, ROC: 0.696, F1_healthy: 0.454\n",
      "\n",
      "[37,   320] Validation loss: 15.732, ROC: 0.708, F1_healthy: 0.390 \n",
      "\n",
      "[38,   320] loss: 17.402, ROC: 0.675, F1_healthy: 0.436\n",
      "\n",
      "[38,   320] Validation loss: 15.864, ROC: 0.660, F1_healthy: 0.398 \n",
      "\n",
      "[39,   320] loss: 16.960, ROC: 0.701, F1_healthy: 0.419\n",
      "\n",
      "[39,   320] Validation loss: 15.375, ROC: 0.739, F1_healthy: 0.396 \n",
      "\n",
      "[40,   320] loss: 16.747, ROC: 0.728, F1_healthy: 0.489\n",
      "\n",
      "[40,   320] Validation loss: 15.290, ROC: 0.733, F1_healthy: 0.421 \n",
      "\n",
      "[41,   320] loss: 16.602, ROC: 0.746, F1_healthy: 0.500\n",
      "\n",
      "[41,   320] Validation loss: 15.109, ROC: 0.745, F1_healthy: 0.421 \n",
      "\n",
      "[42,   320] loss: 16.539, ROC: 0.741, F1_healthy: 0.504\n",
      "\n",
      "[42,   320] Validation loss: 15.577, ROC: 0.713, F1_healthy: 0.364 \n",
      "\n",
      "[43,   320] loss: 16.592, ROC: 0.738, F1_healthy: 0.476\n",
      "\n",
      "[43,   320] Validation loss: 15.005, ROC: 0.755, F1_healthy: 0.434 \n",
      "\n",
      "[44,   320] loss: 17.402, ROC: 0.680, F1_healthy: 0.444\n",
      "\n",
      "[44,   320] Validation loss: 15.274, ROC: 0.746, F1_healthy: 0.431 \n",
      "\n",
      "[45,   320] loss: 16.575, ROC: 0.745, F1_healthy: 0.472\n",
      "\n",
      "[45,   320] Validation loss: 15.621, ROC: 0.700, F1_healthy: 0.420 \n",
      "\n",
      "[46,   320] loss: 16.535, ROC: 0.742, F1_healthy: 0.472\n",
      "\n",
      "[46,   320] Validation loss: 15.059, ROC: 0.748, F1_healthy: 0.442 \n",
      "\n",
      "[47,   320] loss: 16.249, ROC: 0.760, F1_healthy: 0.506\n",
      "\n",
      "[47,   320] Validation loss: 15.277, ROC: 0.733, F1_healthy: 0.437 \n",
      "\n",
      "[48,   320] loss: 16.405, ROC: 0.742, F1_healthy: 0.473\n",
      "\n",
      "[48,   320] Validation loss: 15.421, ROC: 0.724, F1_healthy: 0.429 \n",
      "\n",
      "[49,   320] loss: 16.192, ROC: 0.773, F1_healthy: 0.538\n",
      "\n",
      "[49,   320] Validation loss: 14.784, ROC: 0.765, F1_healthy: 0.465 \n",
      "\n",
      "[50,   320] loss: 16.090, ROC: 0.767, F1_healthy: 0.526\n",
      "\n",
      "[50,   320] Validation loss: 14.982, ROC: 0.749, F1_healthy: 0.447 \n",
      "\n",
      "[51,   320] loss: 16.487, ROC: 0.739, F1_healthy: 0.507\n",
      "\n",
      "[51,   320] Validation loss: 15.217, ROC: 0.724, F1_healthy: 0.439 \n",
      "\n",
      "[52,   320] loss: 16.537, ROC: 0.741, F1_healthy: 0.488\n",
      "\n",
      "[52,   320] Validation loss: 14.965, ROC: 0.757, F1_healthy: 0.449 \n",
      "\n",
      "[53,   320] loss: 16.052, ROC: 0.761, F1_healthy: 0.502\n",
      "\n",
      "[53,   320] Validation loss: 15.152, ROC: 0.734, F1_healthy: 0.469 \n",
      "\n",
      "[54,   320] loss: 15.965, ROC: 0.772, F1_healthy: 0.509\n",
      "\n",
      "[54,   320] Validation loss: 15.335, ROC: 0.724, F1_healthy: 0.432 \n",
      "\n",
      "[55,   320] loss: 15.742, ROC: 0.783, F1_healthy: 0.543\n",
      "\n",
      "[55,   320] Validation loss: 14.931, ROC: 0.757, F1_healthy: 0.452 \n",
      "\n",
      "[56,   320] loss: 16.070, ROC: 0.763, F1_healthy: 0.521\n",
      "\n",
      "[56,   320] Validation loss: 14.256, ROC: 0.798, F1_healthy: 0.508 \n",
      "\n",
      "[57,   320] loss: 16.279, ROC: 0.753, F1_healthy: 0.496\n",
      "\n",
      "[57,   320] Validation loss: 15.151, ROC: 0.739, F1_healthy: 0.459 \n",
      "\n",
      "[58,   320] loss: 15.677, ROC: 0.785, F1_healthy: 0.528\n",
      "\n",
      "[58,   320] Validation loss: 14.447, ROC: 0.759, F1_healthy: 0.496 \n",
      "\n",
      "[59,   320] loss: 15.501, ROC: 0.789, F1_healthy: 0.571\n",
      "\n",
      "[59,   320] Validation loss: 14.756, ROC: 0.759, F1_healthy: 0.424 \n",
      "\n",
      "[60,   320] loss: 14.988, ROC: 0.812, F1_healthy: 0.552\n",
      "\n",
      "[60,   320] Validation loss: 14.363, ROC: 0.780, F1_healthy: 0.503 \n",
      "\n",
      "[61,   320] loss: 15.508, ROC: 0.791, F1_healthy: 0.574\n",
      "\n",
      "[61,   320] Validation loss: 14.284, ROC: 0.789, F1_healthy: 0.447 \n",
      "\n",
      "[62,   320] loss: 15.274, ROC: 0.799, F1_healthy: 0.563\n",
      "\n",
      "[62,   320] Validation loss: 14.724, ROC: 0.760, F1_healthy: 0.454 \n",
      "\n",
      "[63,   320] loss: 15.854, ROC: 0.767, F1_healthy: 0.535\n",
      "\n",
      "[63,   320] Validation loss: 14.197, ROC: 0.794, F1_healthy: 0.462 \n",
      "\n",
      "[64,   320] loss: 15.424, ROC: 0.799, F1_healthy: 0.573\n",
      "\n",
      "[64,   320] Validation loss: 15.262, ROC: 0.732, F1_healthy: 0.427 \n",
      "\n",
      "[65,   320] loss: 15.937, ROC: 0.758, F1_healthy: 0.500\n",
      "\n",
      "[65,   320] Validation loss: 14.310, ROC: 0.789, F1_healthy: 0.508 \n",
      "\n",
      "[66,   320] loss: 15.194, ROC: 0.802, F1_healthy: 0.529\n",
      "\n",
      "[66,   320] Validation loss: 14.940, ROC: 0.739, F1_healthy: 0.404 \n",
      "\n",
      "[67,   320] loss: 14.754, ROC: 0.815, F1_healthy: 0.557\n",
      "\n",
      "[67,   320] Validation loss: 14.540, ROC: 0.765, F1_healthy: 0.458 \n",
      "\n",
      "[68,   320] loss: 15.132, ROC: 0.802, F1_healthy: 0.562\n",
      "\n",
      "[68,   320] Validation loss: 15.244, ROC: 0.723, F1_healthy: 0.402 \n",
      "\n",
      "[69,   320] loss: 14.570, ROC: 0.837, F1_healthy: 0.596\n",
      "\n",
      "[69,   320] Validation loss: 14.350, ROC: 0.790, F1_healthy: 0.500 \n",
      "\n",
      "[70,   320] loss: 15.352, ROC: 0.795, F1_healthy: 0.554\n",
      "\n",
      "[70,   320] Validation loss: 15.453, ROC: 0.723, F1_healthy: 0.423 \n",
      "\n",
      "[71,   320] loss: 14.878, ROC: 0.807, F1_healthy: 0.528\n",
      "\n",
      "[71,   320] Validation loss: 14.097, ROC: 0.796, F1_healthy: 0.458 \n",
      "\n",
      "[72,   320] loss: 15.480, ROC: 0.789, F1_healthy: 0.559\n",
      "\n",
      "[72,   320] Validation loss: 14.628, ROC: 0.766, F1_healthy: 0.419 \n",
      "\n",
      "[73,   320] loss: 15.613, ROC: 0.781, F1_healthy: 0.522\n",
      "\n",
      "[73,   320] Validation loss: 15.172, ROC: 0.738, F1_healthy: 0.450 \n",
      "\n",
      "[74,   320] loss: 15.754, ROC: 0.766, F1_healthy: 0.483\n",
      "\n",
      "[74,   320] Validation loss: 14.621, ROC: 0.765, F1_healthy: 0.432 \n",
      "\n",
      "[75,   320] loss: 15.252, ROC: 0.790, F1_healthy: 0.500\n",
      "\n",
      "[75,   320] Validation loss: 13.654, ROC: 0.817, F1_healthy: 0.514 \n",
      "\n",
      "[76,   320] loss: 14.805, ROC: 0.811, F1_healthy: 0.560\n",
      "\n",
      "[76,   320] Validation loss: 14.391, ROC: 0.779, F1_healthy: 0.451 \n",
      "\n",
      "[77,   320] loss: 15.711, ROC: 0.776, F1_healthy: 0.531\n",
      "\n",
      "[77,   320] Validation loss: 14.501, ROC: 0.784, F1_healthy: 0.465 \n",
      "\n",
      "[78,   320] loss: 15.346, ROC: 0.788, F1_healthy: 0.532\n",
      "\n",
      "[78,   320] Validation loss: 14.761, ROC: 0.745, F1_healthy: 0.453 \n",
      "\n",
      "[79,   320] loss: 14.748, ROC: 0.815, F1_healthy: 0.575\n",
      "\n",
      "[79,   320] Validation loss: 13.515, ROC: 0.822, F1_healthy: 0.508 \n",
      "\n",
      "[80,   320] loss: 15.430, ROC: 0.796, F1_healthy: 0.563\n",
      "\n",
      "[80,   320] Validation loss: 14.718, ROC: 0.773, F1_healthy: 0.428 \n",
      "\n",
      "[81,   320] loss: 14.462, ROC: 0.828, F1_healthy: 0.575\n",
      "\n",
      "[81,   320] Validation loss: 13.869, ROC: 0.806, F1_healthy: 0.536 \n",
      "\n",
      "[82,   320] loss: 14.773, ROC: 0.814, F1_healthy: 0.567\n",
      "\n",
      "[82,   320] Validation loss: 13.301, ROC: 0.829, F1_healthy: 0.532 \n",
      "\n",
      "[83,   320] loss: 14.569, ROC: 0.822, F1_healthy: 0.599\n",
      "\n",
      "[83,   320] Validation loss: 14.644, ROC: 0.758, F1_healthy: 0.442 \n",
      "\n",
      "[84,   320] loss: 14.865, ROC: 0.802, F1_healthy: 0.540\n",
      "\n",
      "[84,   320] Validation loss: 13.992, ROC: 0.794, F1_healthy: 0.471 \n",
      "\n",
      "[85,   320] loss: 15.168, ROC: 0.801, F1_healthy: 0.550\n",
      "\n",
      "[85,   320] Validation loss: 14.767, ROC: 0.766, F1_healthy: 0.441 \n",
      "\n",
      "[86,   320] loss: 14.345, ROC: 0.829, F1_healthy: 0.577\n",
      "\n",
      "[86,   320] Validation loss: 13.649, ROC: 0.806, F1_healthy: 0.506 \n",
      "\n",
      "[87,   320] loss: 14.578, ROC: 0.822, F1_healthy: 0.570\n",
      "\n",
      "[87,   320] Validation loss: 14.599, ROC: 0.764, F1_healthy: 0.420 \n",
      "\n",
      "[88,   320] loss: 14.440, ROC: 0.828, F1_healthy: 0.583\n",
      "\n",
      "[88,   320] Validation loss: 14.616, ROC: 0.766, F1_healthy: 0.446 \n",
      "\n",
      "[89,   320] loss: 13.986, ROC: 0.840, F1_healthy: 0.588\n",
      "\n",
      "[89,   320] Validation loss: 14.539, ROC: 0.769, F1_healthy: 0.480 \n",
      "\n",
      "[90,   320] loss: 15.133, ROC: 0.797, F1_healthy: 0.558\n",
      "\n",
      "[90,   320] Validation loss: 15.823, ROC: 0.716, F1_healthy: 0.428 \n",
      "\n",
      "[91,   320] loss: 15.143, ROC: 0.801, F1_healthy: 0.571\n",
      "\n",
      "[91,   320] Validation loss: 14.944, ROC: 0.755, F1_healthy: 0.430 \n",
      "\n",
      "[92,   320] loss: 14.113, ROC: 0.838, F1_healthy: 0.584\n",
      "\n",
      "[92,   320] Validation loss: 14.664, ROC: 0.762, F1_healthy: 0.442 \n",
      "\n",
      "[93,   320] loss: 14.886, ROC: 0.808, F1_healthy: 0.542\n",
      "\n",
      "[93,   320] Validation loss: 14.823, ROC: 0.762, F1_healthy: 0.458 \n",
      "\n",
      "[94,   320] loss: 14.303, ROC: 0.831, F1_healthy: 0.619\n",
      "\n",
      "[94,   320] Validation loss: 14.701, ROC: 0.766, F1_healthy: 0.481 \n",
      "\n",
      "[95,   320] loss: 14.091, ROC: 0.837, F1_healthy: 0.592\n",
      "\n",
      "[95,   320] Validation loss: 14.765, ROC: 0.763, F1_healthy: 0.451 \n",
      "\n",
      "[96,   320] loss: 14.547, ROC: 0.821, F1_healthy: 0.580\n",
      "\n",
      "[96,   320] Validation loss: 14.960, ROC: 0.765, F1_healthy: 0.443 \n",
      "\n",
      "[97,   320] loss: 13.650, ROC: 0.847, F1_healthy: 0.577\n",
      "\n",
      "[97,   320] Validation loss: 13.819, ROC: 0.797, F1_healthy: 0.512 \n",
      "\n",
      "[98,   320] loss: 14.652, ROC: 0.820, F1_healthy: 0.574\n",
      "\n",
      "[98,   320] Validation loss: 15.180, ROC: 0.761, F1_healthy: 0.421 \n",
      "\n",
      "[99,   320] loss: 14.183, ROC: 0.837, F1_healthy: 0.612\n",
      "\n",
      "[99,   320] Validation loss: 15.435, ROC: 0.749, F1_healthy: 0.421 \n",
      "\n",
      "[100,   320] loss: 14.013, ROC: 0.834, F1_healthy: 0.600\n",
      "\n",
      "[100,   320] Validation loss: 13.912, ROC: 0.797, F1_healthy: 0.475 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [01:20, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100,   320] Validation loss: 14.101, ROC: 0.785, F1_healthy: 0.466 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=2)\n",
    "\n",
    "fold_rocauc = []\n",
    "fold_f1healthy = []\n",
    "fold_loss = []\n",
    "for idx, (train_index, test_index) in tqdm(enumerate(kf.split(cuda_image_array))):\n",
    "    train_dataset = RetinaDataset(data_indices=train_index)\n",
    "    test_dataset = RetinaDataset(data_indices=test_index)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    ciciknet = CicikNet().to(device)\n",
    "    # optimizer = optim.SGD(ciciknet.parameters(), lr=0.001, momentum = 0.9) # Understand why ADAM does not work with batchsize = 1\n",
    "    optimizer = optim.SGD(ciciknet.parameters(), lr=0.001, momentum = 0.9)\n",
    "    \n",
    "    for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "        loss_train, rocauc_train, f1healthy_train= model_train_loop(ciciknet,train_dataloader)\n",
    "        loss_test, rocauc_test, f1healthy_test = model_test_loop(ciciknet,test_dataloader)\n",
    "        \n",
    "        writer.add_scalars('training/val rocauc', {\"train_rocauc\":rocauc_train,\"validation_rocauc\":rocauc_test}, epoch +1)\n",
    "        writer.add_scalars('training/val healthy_f1', {\"f1healthy_train\":f1healthy_train,\"f1healthy_test\":f1healthy_test}, epoch +1)\n",
    "        writer.add_scalars('training/val loss', {\"loss_train\":loss_train,\"loss_test\":loss_test}, epoch +1)\n",
    "        \n",
    "        \n",
    "    loss_, rocauc, f1healthy = model_test_loop(ciciknet,test_dataloader)\n",
    "    \n",
    "    fold_rocauc.append(rocauc)\n",
    "    fold_f1healthy.append(f1healthy)\n",
    "    fold_loss.append(loss_)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80e73972-9af7-4b17-b547-a1e196198ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.7846, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "print(fold_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3f56415-ed3f-4830-9b4e-646109647db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46590909090909094]\n"
     ]
    }
   ],
   "source": [
    "print(fold_f1healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfbb38-67a7-4cd3-bc5d-46ea9ac4b1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186bac6-9bb7-4bcf-b056-18edd3aae630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
