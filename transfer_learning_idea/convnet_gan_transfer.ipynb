{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ed45bf-37f1-4189-b696-5707062d2ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.16.0-unknown is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/john/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/john/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 2.22.1ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.augmentations.dropout.grid_dropout import GridDropout\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b28b366-738f-41db-8047-3de5ca425f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2db926-014f-4233-8ea8-18de6828d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetinaTransform(image):\n",
    "    # Bringing image to 0-1 range, #ATTENTION: CHECK IF ALL IMAGES min max is 0 and 255\n",
    "    image = (image / 255)*2-1\n",
    "    \n",
    "    \n",
    "    image = resize(image, (64,64),anti_aliasing=False) # resizing image because original does not fit in memory.\n",
    "    \n",
    "    label = image.copy()\n",
    "    grid_drop = GridDropout(ratio=0.5, unit_size_min=10, unit_size_max=50, fill_value=1, random_offset=True, always_apply=True)\n",
    "    image = grid_drop(image=image)[\"image\"]\n",
    "    # Bringing data to CHW format\n",
    "    # N is a batch size, C denotes a number of channels, \n",
    "    # H is a height of input planes in pixels, and W is width in pixels.\n",
    "    image = image.transpose([2,0,1])\n",
    "    label = label.transpose([2,0,1]) #No need to transpose lables\n",
    "    \n",
    "    #Fixing dtype to avoid runtime error and save memory\n",
    "    image = torch.tensor(image ,dtype=torch.float32)\n",
    "    label = torch.tensor(label ,dtype=torch.float32)\n",
    "    \n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a6109b-def2-433d-ba14-ac74117cdee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9200/9200 [13:36<00:00, 11.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset into memory\n",
    "if 'image_array' not in globals():\n",
    "    image_array = []\n",
    "    data_paths= glob(\"../data/ODIR-5K/ODIR-5K/Testing Images/*\")+glob(\"../data/ODIR-5K/ODIR-5K/Training Images/*\")+glob(\"../data/REFUGE/Images_Square/*\")\n",
    "    data_paths = data_paths\n",
    "    local_transform = RetinaTransform\n",
    "\n",
    "\n",
    "    for image_name in tqdm(data_paths):\n",
    "        image = io.imread(image_name)\n",
    "        image,label = local_transform(image)\n",
    "        image_array.append((image,label))\n",
    "        \n",
    "    with open(\"image_array.pkl\", \"wb\") as f:\n",
    "        pickle.dump(image_array,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "386defcf-7fdf-4cba-9043-33375b017197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"image_array.pkl\", \"rb\") as f:\n",
    "#     image_array = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076ec0d4-f4be-4610-bc6c-e24ec30fc161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalize the images between -1 and 1\n",
    "# Tanh as the last layer of the generator output\n",
    "\n",
    "# In GAN papers, the loss function to optimize G is min (log 1-D), but in practice folks practically use max log D\n",
    "\n",
    "#     because the first formulation has vanishing gradients early on\n",
    "#     Goodfellow et. al (2014)\n",
    "\n",
    "# In practice, works well:\n",
    "\n",
    "#     Flip labels when training generator: real = fake, fake = real\n",
    "\n",
    "# the stability of the GAN game suffers if you have sparse gradients\n",
    "# LeakyReLU = good (in both G and D)\n",
    "\n",
    "\n",
    "# optim.Adam rules!\n",
    "#     See Radford et. al. 2015\n",
    "# Use SGD for discriminator and ADAM for generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b5bba0-8987-4800-b363-42e48177a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMSNETGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_conv = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1,padding=1)\n",
    "        self.linear_encoder = nn.Linear(3*64*64, 2048)\n",
    "        self.linear_decoder = nn.Linear(2048, 3*64*64)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_conv(x)\n",
    "        x = self.tanh(x)\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "        x = self.linear_encoder(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear_decoder(x)\n",
    "        x = self.tanh(x)\n",
    "        x = x.reshape(-1,3,64,64)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c3dbf0a-aab3-4d9f-9428-79525cd88933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMSNETDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EMSNETDiscriminator, self).__init__()\n",
    "        self.ndf = 10\n",
    "        self.predict = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(3, self.ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.ndf, self.ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "450f4dcb-767a-4a02-83ad-201c1b035e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMSNETGAN(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generator = EMSNETGenerator()\n",
    "        self.discriminator = EMSNETDiscriminator()\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.automatic_optimization = False\n",
    "        \n",
    "    def forward(self, img):\n",
    "        return self.generator(img)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        imgs, labels = batch\n",
    "        \n",
    "        optimizer_g, optimizer_d = self.optimizers()\n",
    "        \n",
    "        self.toggle_optimizer(optimizer_g)\n",
    "        valid = torch.ones(imgs.size(0), 1)\n",
    "        valid = valid.type_as(imgs)\n",
    "        \n",
    "        \n",
    "        if optimizer_idx == 0:\n",
    "            \n",
    "            real_label_ = torch.ones(labels.size(0),device=device)\n",
    "            real_output_ = self.discriminator(labels).view(-1)\n",
    "            err_real = self.criterion(real_output_, real_label_)\n",
    "            fake_label_ = torch.zeros(imgs.size(0),device=device)\n",
    "            fake_output_ = self.discriminator(self.generator(imgs)).view(-1)\n",
    "            err_fake = self.criterion(fake_output_, fake_label_)\n",
    "            \n",
    "            self.log(\"dlos\", err_real+err_fake, prog_bar=True)\n",
    "            return err_real+err_fake\n",
    "\n",
    "        # train generator\n",
    "        if optimizer_idx == 1:\n",
    "            \n",
    "            #maximize log(D(G(z))) \n",
    "            real_label_ = torch.ones(labels.size(0),device=device)\n",
    "            fake_output_ = self.discriminator(self.generator(imgs)).view(-1)\n",
    "            err_real = self.criterion(fake_output_, real_label_)\n",
    "            self.log(\"glos\", err_real, prog_bar=True)\n",
    "            \n",
    "            return err_real\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        return [opt_d, opt_g], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3d4b4fe-28cc-4d06-a94a-b7093510b642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# discriminant = EMSNETDiscriminator()\n",
    "# generant = EMSNETGenerator()\n",
    "# loss_ = nn.BCELoss()\n",
    "# with torch.no_grad():\n",
    "#     for idx,i in enumerate(val_dataloader):\n",
    "#         # print(i[0].shape, generant(i[0]).shape)\n",
    "#         print(i[0].shape, discriminant(i[0]))\n",
    "#         real_label = torch.ones(i[0].size(0))\n",
    "#         output = generant(i[1])\n",
    "#         errD_real = loss_(output, real_label)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c33fea2d-5297-43bd-956d-7d31e9485df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_indices, transform=None):\n",
    "        \n",
    "        self.data = [image_array[idx] for idx in data_indices]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "296d4f22-d256-46ad-9b39-20b6b8cfd302",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RetinaDataset(data_indices=np.arange(0,len(image_array)-50))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=False, num_workers=8)\n",
    "\n",
    "val_dataset = RetinaDataset(data_indices=np.arange(len(image_array)-50,len(image_array)))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05d528c1-74e4-401d-8592-ca927cf17dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_dataset[0][0].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b3fc827-4e05-43e8-9ab8-da9050366e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "emsnet = EMSNETGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f64a5a55-1635-4f9f-8291-b57b1908f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "# class LitProgressBar(TQDMProgressBar):\n",
    "#     def init_validation_tqdm(self):\n",
    "#         bar = super().init_validation_tqdm()\n",
    "#         bar.set_description(\"running validation...\")\n",
    "#         return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9647aea-b48d-4bfc-a3b2-42818204483d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.16.0-unknown is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/john/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/john/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 2.22.1ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=1, accelerator='gpu', gradient_clip_val=0.5)\n",
    "# tuner = Tuner(trainer)\n",
    "# tuner.scale_batch_size(emsnet, mode=\"binsearch\")\n",
    "# trainer.fit(model=emsnet, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f019005-cf3a-4806-8b3b-0f11ff4c8e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Training with multiple optimizers is only supported with manual optimization. Set `self.automatic_optimization = False`, then access your optimizers in `training_step` with `opt1, opt2, ... = self.optimizers()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memsnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    518\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 520\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    550\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    555\u001b[0m     ckpt_path,\n\u001b[1;32m    556\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    558\u001b[0m )\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:911\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m    910\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/single_device.py:74\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: pl\u001b[38;5;241m.\u001b[39mTrainer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_to_device()\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:148\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39msetup(trainer)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_precision_plugin()\n\u001b[1;32m    150\u001b[0m _optimizers_to_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:138\u001b[0m, in \u001b[0;36mStrategy.setup_optimizers\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler_configs \u001b[38;5;241m=\u001b[39m \u001b[43m_init_optimizers_and_lr_schedulers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:185\u001b[0m, in \u001b[0;36m_init_optimizers_and_lr_schedulers\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    179\u001b[0m optimizers, lr_schedulers, monitor \u001b[38;5;241m=\u001b[39m _configure_optimizers(optim_conf)\n\u001b[1;32m    180\u001b[0m lr_scheduler_configs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    181\u001b[0m     _configure_schedulers_automatic_opt(lr_schedulers, monitor)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mautomatic_optimization\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _configure_schedulers_manual_opt(lr_schedulers)\n\u001b[1;32m    184\u001b[0m )\n\u001b[0;32m--> 185\u001b[0m \u001b[43m_validate_multiple_optimizers_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m _validate_optimizers_attached(optimizers, lr_scheduler_configs)\n\u001b[1;32m    187\u001b[0m _validate_scheduler_api(lr_scheduler_configs, model)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:341\u001b[0m, in \u001b[0;36m_validate_multiple_optimizers_support\u001b[0;34m(optimizers, model)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_multiple_optimizers_support\u001b[39m(optimizers: List[Optimizer], model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mautomatic_optimization \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 341\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    342\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining with multiple optimizers is only supported with manual optimization. Set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    343\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `self.automatic_optimization = False`, then access your optimizers in `training_step` with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    344\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `opt1, opt2, ... = self.optimizers()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Training with multiple optimizers is only supported with manual optimization. Set `self.automatic_optimization = False`, then access your optimizers in `training_step` with `opt1, opt2, ... = self.optimizers()`."
     ]
    }
   ],
   "source": [
    "trainer.fit(model=emsnet, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ec7fc4-f9e5-48a7-afd6-d92e21835937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emsnet.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647d748-c541-474c-8236-0687be1a2b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emsnet.eval()\n",
    "with torch.no_grad():\n",
    "    for idx,i in enumerate(train_dataloader):\n",
    "        print(i[0].shape,i[1].shape)\n",
    "        output = emsnet.generator(i[0])\n",
    "        # print(emsnet.discriminator(output))\n",
    "        # print(emsnet.discriminator(i[1]))\n",
    "        plt.imshow(output[0].cpu().detach().numpy().transpose(2,1,0))\n",
    "        plt.show()\n",
    "        plt.imshow(i[1][0].permute(1,2,0))\n",
    "        plt.show()\n",
    "        plt.imshow(i[0][0].permute(1,2,0))\n",
    "        plt.show()\n",
    "        if idx == 4: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efcfbb38-67a7-4cd3-bc5d-46ea9ac4b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308341ab-51e0-45e3-9f0b-f61c6d00ac87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
