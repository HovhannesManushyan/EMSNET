{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:11:31.242515Z",
     "end_time": "2023-05-04T21:11:34.308683Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def random_data(m=1024, n=1):\n",
    "    x_train = torch.rand(m, n)\n",
    "    x_test = torch.rand(m // 2, n)\n",
    "    y_train = (x_train[:, 0] > 0.5).float().unsqueeze(0).t()\n",
    "    y_test = (x_test[:, 0] > 0.5).float().unsqueeze(0).t()\n",
    "    return x_train, y_train, x_test, y_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:11:34.312846Z",
     "end_time": "2023-05-04T21:11:34.315895Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = random_data(m=10000)\n",
    "\n",
    "\n",
    "class SampleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(1, 16)\n",
    "        self.layer2 = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "sample_model = SampleModel()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(sample_model.parameters())\n",
    "batch_size = 10\n",
    "data = torch.split(x_train, batch_size)\n",
    "y = torch.split(y_train, batch_size)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for i in range(len(data)):\n",
    "        optimizer.zero_grad()\n",
    "        output = sample_model(data[i])\n",
    "        loss = loss_fn(output, y[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accuracy = (output.round() == y[i]).float().mean()\n",
    "        print('Epoch {} Loss {} Accuracy {}'.format(epoch, loss.item(), accuracy))\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_test = sample_model(x_test)\n",
    "    accuracy_test = (output_test.round() == y_test).float().mean()\n",
    "    print('Test Accuracy:', accuracy_test.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:11:34.325540Z",
     "end_time": "2023-05-04T21:11:38.007806Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def test_layer_by_layer_model(sample_model, data):\n",
    "    layer1_weight = sample_model.layer1.weight.data.T\n",
    "    layer1_bias = sample_model.layer1.bias.data\n",
    "    layer2_weight = sample_model.layer2.weight.data.T\n",
    "    layer2_bias = sample_model.layer2.bias.data\n",
    "    for data_point in data:\n",
    "        layer_1 = nn.Sigmoid()(data_point.mm(layer1_weight) + layer1_bias)\n",
    "        layer_2 = nn.Sigmoid()(layer_1.mm(layer2_weight) + layer2_bias)\n",
    "        assert layer_2 == sample_model(data_point)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:11:38.013532Z",
     "end_time": "2023-05-04T21:11:38.016267Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = torch.split(x_test, 1)\n",
    "\n",
    "test_layer_by_layer_model(sample_model, data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:11:38.021016Z",
     "end_time": "2023-05-04T21:11:38.817195Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Encrypting data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the TenSEAL security context\n",
    "def create_ctx():\n",
    "    \"\"\"Helper for creating the CKKS context.\n",
    "    CKKS params:\n",
    "        - Polynomial degree: 8192.\n",
    "        - Coefficient modulus size: [40, 21, 21, 21, 21, 21, 21, 40].\n",
    "        - Scale: 2 ** 21.\n",
    "        - The setup requires the Galois keys for evaluating the convolutions.\n",
    "    \"\"\"\n",
    "    bits_scale = 26\n",
    "\n",
    "    poly_mod_degree = 16384\n",
    "\n",
    "    coeff_mod_bit_sizes = [31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale,\n",
    "                           bits_scale, 31]\n",
    "    ctx = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "    ctx.global_scale = pow(2, bits_scale)\n",
    "    ctx.generate_galois_keys()\n",
    "\n",
    "    # We prepare the context for the server, by making it public(we drop the secret key)\n",
    "    server_context = ctx.copy()\n",
    "    server_context.make_context_public()\n",
    "\n",
    "    return ctx, server_context\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:11:38.816230Z",
     "end_time": "2023-05-04T21:11:38.821357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper for encoding the image\n",
    "def prepare_input(ctx, plain_input):\n",
    "    enc_input = ts.ckks_vector(ctx, plain_input)\n",
    "    return enc_input\n",
    "\n",
    "\n",
    "def prepare_input_encrypted(context: bytes, ckks_vector: bytes) -> ts.CKKSVector:\n",
    "    try:\n",
    "        ctx = ts.context_from(context)\n",
    "        enc_x = ts.ckks_vector_from(ctx, ckks_vector)\n",
    "    except:\n",
    "        raise ValueError(\"cannot deserialize context or ckks_vector\")\n",
    "    try:\n",
    "        _ = ctx.galois_keys()\n",
    "    except:\n",
    "        raise ValueError(\"the context doesn't hold galois keys\")\n",
    "    return enc_x\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:11:38.824468Z",
     "end_time": "2023-05-04T21:11:38.827385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "context, server_context = create_ctx()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:11:48.263632Z",
     "end_time": "2023-05-04T21:11:48.272316Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    np.abs(np.array(prepare_input(context, torch.flatten(x_test)).decrypt()) - np.array(torch.flatten(x_test))))\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Single number encryption error\")\n",
    "plt.savefig(\"enc_err\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:33:54.180033Z",
     "end_time": "2023-05-04T21:33:54.565551Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "# encrypted model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer1_weight = sample_model.layer1.weight.data.T\n",
    "layer1_bias = sample_model.layer1.bias.data\n",
    "layer2_weight = sample_model.layer2.weight.data.T\n",
    "layer2_bias = sample_model.layer2.bias.data\n",
    "        # layer_1 = nn.Sigmoid()(data_point.mm(layer1_weight) + layer1_bias)\n",
    "        # layer_2 = nn.Sigmoid()(layer_1.mm(layer2_weight) + layer2_bias)\n",
    "x_train, y_train, x_test, y_test = random_data(m=1000)\n",
    "\n",
    "# Decryption of result\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "errors = []\n",
    "mean_err = []\n",
    "for data, target in zip(x_train, y_train):\n",
    "    # Encoding and encryption\n",
    "    x_enc = prepare_input(context, data)\n",
    "    enc_x = x_enc.mm(layer1_weight) + layer1_bias\n",
    "    enc_x = nn.Sigmoid()(torch.tensor(enc_x.decrypt()))\n",
    "    enc_x = prepare_input(context, enc_x)\n",
    "    # enc_x = -0.004*enc_x*enc_x*enc_x+ 0.197*enc_x + 0.5\n",
    "    enc_output = enc_x.mm(layer2_weight) + layer2_bias\n",
    "    # enc_output = -0.004*enc_x*enc_x*enc_x+ 0.197*enc_x + 0.5\n",
    "    # Decryption of result\n",
    "    output = enc_output.decrypt()\n",
    "    output = nn.Sigmoid()(torch.tensor(output))\n",
    "\n",
    "    output = torch.tensor(output).view(1, -1)\n",
    "    not_enc_model_output = sample_model(torch.tensor(data).type(torch.float))\n",
    "    mean_err.append(torch.abs(not_enc_model_output - output))\n",
    "    # compute loss\n",
    "    if (not_enc_model_output > 0.5) == (output > 0.5):\n",
    "        errors.append(1)\n",
    "    else:\n",
    "        errors.append(0)\n",
    "print(f\"Accuracy for binary prediction : {sum(errors) / len(errors)}\")\n",
    "mean_err = sum(mean_err) / len(x_train)\n",
    "print(f\"Mean Error per value for prediction {mean_err}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
