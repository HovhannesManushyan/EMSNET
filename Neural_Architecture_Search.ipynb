{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ed45bf-37f1-4189-b696-5707062d2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/home/elina/PycharmProjects/capstone_project\")\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "from modules.model.main import ConvCatNet\n",
    "from modules.data.preprocessing import PreProcess\n",
    "\n",
    "import torch\n",
    "import tenseal as ts\n",
    "import numpy as np\n",
    "\n",
    "from modules.encryption.keys import create_ctx\n",
    "def size_is_ok():\n",
    "    img = preprocessor.cuda_image_array.copy()[0][0]\n",
    "\n",
    "    conv1_weight = net.conv1.weight.data.view(\n",
    "        -1, net.conv1.kernel_size[0],\n",
    "        net.conv1.kernel_size[1]\n",
    "    ).tolist()\n",
    "    conv1_bias = net.conv1.bias.data.tolist()\n",
    "    nk = img.tolist().copy()[0]\n",
    "\n",
    "    x_enc_0, windows_nb_0 = ts.im2col_encoding(\n",
    "        context, nk, 3,\n",
    "        3, 1\n",
    "    )\n",
    "    y = x_enc_0.conv2d_im2col(conv1_weight[0], windows_nb_0) + conv1_bias[0]\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b28b366-738f-41db-8047-3de5ca425f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = 20  # poly degree /2 should be bigger than image to columns for conv size\n",
    "context, server_context = create_ctx(bits_scale=30,num_mul=7)  # scale up as working with floats,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c2db926-014f-4233-8ea8-18de6828d24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1920 [00:00<09:44,  3.28it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = PreProcess(image_size=image_size)\n",
    "train_dataloader, test_dataloader = preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a29b310-0f04-4801-95bc-52611702d998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvCatNet(\n",
      "  (lrelu): LeakyReLU(negative_slope=0.1)\n",
      "  (conv1): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(3, 1, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=324, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ConvCatNet(image_size=image_size).to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tenseal.tensors.ckksvector.CKKSVector object at 0x7f1f2cadb1f0>\n"
     ]
    }
   ],
   "source": [
    "size_is_ok()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "bauc = BinaryAUROC(thresholds=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def model_train_loop(net, train_dataloader):\n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "\n",
    "    for idx, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs\n",
    "        # print(i,data)\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs.flatten(), labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=10)\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        predictions.append(outputs.flatten())\n",
    "        ground_truth.append(labels.flatten())\n",
    "\n",
    "    # net.to('cpu')\n",
    "    # plot_grad_flow(net.named_parameters())\n",
    "    # plt.show()\n",
    "    # net.to(device)\n",
    "\n",
    "    predictions = torch.cat(predictions)\n",
    "    ground_truth = torch.cat(ground_truth)\n",
    "\n",
    "    healthy_f1 = f1_score((predictions > 0.5).float().cpu(), ground_truth.cpu(), pos_label=0)\n",
    "    rocauc = bauc(predictions, ground_truth)\n",
    "    print(\n",
    "        '[%d, %5d] loss: %.3f, ROC: %.3f, F1_healthy: %.3f\\n' % (epoch + 1, idx + 1, running_loss, rocauc, healthy_f1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def model_test_loop(net, test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        test_predictions = []\n",
    "        test_ground_truth = []\n",
    "\n",
    "        for idx, data in enumerate(test_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs.flatten(), labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            test_predictions.append(outputs.flatten())\n",
    "            test_ground_truth.append(labels.flatten())\n",
    "\n",
    "        test_predictions = torch.cat(test_predictions)\n",
    "        test_ground_truth = torch.cat(test_ground_truth)\n",
    "\n",
    "        healthy_f1 = f1_score((test_predictions > 0.5).float().cpu(), test_ground_truth.cpu(), pos_label=0)\n",
    "        rocauc = bauc(test_predictions, test_ground_truth)\n",
    "        print('[%d, %5d] Validation loss: %.3f, ROC: %.3f, F1_healthy: %.3f \\n' % (\n",
    "            epoch + 1, idx + 1, running_loss, rocauc, healthy_f1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# f1_score((predictions>0.5).float().cpu(),ground_truth.cpu(),pos_label=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# print(len(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.722, ROC: 0.000, F1_healthy: 0.000\n",
      "\n",
      "[1,     2] Validation loss: 1.438, ROC: 0.000, F1_healthy: 0.000 \n",
      "\n",
      "[2,     1] loss: 0.721, ROC: 0.000, F1_healthy: 0.000\n",
      "\n",
      "[2,     2] Validation loss: 1.433, ROC: 0.000, F1_healthy: 0.000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elina/anaconda3/envs/capstone_project/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/elina/anaconda3/envs/capstone_project/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/elina/anaconda3/envs/capstone_project/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/elina/anaconda3/envs/capstone_project/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MODEL learns the trivial case of all 1s, which means it has capacity to learn:\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    model_train_loop(net, train_dataloader)\n",
    "    model_test_loop(net, test_dataloader)\n",
    "\n",
    "\n",
    "# print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# enc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c16a75e-5610-444e-9483-45d80e089dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncConvNet:\n",
    "\n",
    "    def __init__(self, torch_nn):\n",
    "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
    "            -1, torch_nn.conv1.kernel_size[0],\n",
    "            torch_nn.conv1.kernel_size[1]\n",
    "        ).tolist()\n",
    "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
    "\n",
    "        self.conv2_weight = torch_nn.conv2.weight.data.view(\n",
    "            -1, torch_nn.conv2.kernel_size[0],\n",
    "            torch_nn.conv2.kernel_size[1]\n",
    "        ).tolist()\n",
    "        self.conv2_bias = torch_nn.conv2.bias.data.tolist()\n",
    "\n",
    "        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n",
    "        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n",
    "\n",
    "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
    "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
    "\n",
    "\n",
    "    def forward(self, enc_x, windows_nb,windows_nb_2=0):\n",
    "        # conv layer\n",
    "        enc_channels = 0\n",
    "        for ind, kernel in enumerate(self.conv1_weight):\n",
    "            y = enc_x[ind].conv2d_im2col(kernel, windows_nb) + self.conv1_bias[0]\n",
    "\n",
    "            print(\"one channel\")\n",
    "            print(y.shape)\n",
    "            enc_channels+=y\n",
    "            # enc_channels.append(y)\n",
    "\n",
    "        # enc_x_conv_1 = ts.CKKSVector.pack_vectors(enc_channels)\n",
    "        print(\"the conv shape\")\n",
    "        print(enc_channels.shape)\n",
    "\n",
    "        # enc_channels_2 = 0\n",
    "        # for ind, kernel in enumerate(self.conv2_weight):\n",
    "        #     y = enc_x[ind+3].conv2d_im2col(kernel, windows_nb_2) + self.conv2_bias[0]\n",
    "        #\n",
    "        #     print(\"one channel\")\n",
    "        #     print(y.shape)\n",
    "        #     enc_channels_2+=y\n",
    "        #\n",
    "        # enc_x_conv_2 = ts.CKKSVector.pack_vectors([enc_channels,enc_channels_2])\n",
    "        # print(enc_x_conv_2.shape)\n",
    "\n",
    "        # pack all channels into a single flattened vector\n",
    "        # enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
    "        enc_x = enc_channels\n",
    "        # fc1 layer\n",
    "        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n",
    "        # square activation\n",
    "        enc_x = EncConvNet.relu(enc_x)\n",
    "        # fc2 layer\n",
    "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
    "        enc_x = EncConvNet.sigmoid(enc_x)\n",
    "        return enc_x\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        # We use the polynomial approximation of degree 3\n",
    "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
    "        # from https://eprint.iacr.org/2018/462.pdf\n",
    "        # which fits the function pretty well in the range [-5,5]\n",
    "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(enc_x):\n",
    "        # We use the polynomial approximation of degree 3\n",
    "        # relu(x) = 0.47+0.5*x+0.09*(x**2)-1.7*e-10*(x**3)\n",
    "        # from https://openreview.net/attachment?id=rkxsgkHKvH&name=original_pdf\n",
    "        # which fits the function pretty well in the range [-5,5]\n",
    "        return enc_x.polyval([0.47, 0.5, 0.09, -0.0000000007])\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa3e8d73-4b64-4c95-8761-ec72af0cc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_net = EncConvNet(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one conv1\n",
      "torch.Size([1, 3, 20, 20])\n",
      "torch.Size([1, 1, 18, 18])\n",
      "torch.Size([1, 1, 16, 16])\n",
      "tensor([[0.4870]], grad_fn=<SigmoidBackward0>)\n",
      "one conv1\n",
      "torch.Size([1, 3, 20, 20])\n",
      "torch.Size([1, 1, 18, 18])\n",
      "torch.Size([1, 1, 16, 16])\n",
      "tensor([[0.4898]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(test_dataloader, 0):\n",
    "    inputs, labels = data\n",
    "    print(\"one conv1\")\n",
    "    print(inputs.shape)\n",
    "    print(net.conv1(inputs).shape)\n",
    "    print(net.conv2(inputs).shape)\n",
    "    outputs = net(inputs)\n",
    "    print(outputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n",
      "one channel\n",
      "[324]\n",
      "one channel\n",
      "[324]\n",
      "one channel\n",
      "[324]\n",
      "the conv shape\n",
      "[324]\n",
      "[0.4841976302148786]\n",
      "torch.Size([20, 20])\n",
      "one channel\n",
      "[324]\n",
      "one channel\n",
      "[324]\n",
      "one channel\n",
      "[324]\n",
      "the conv shape\n",
      "[324]\n",
      "[0.48422946235151393]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    img = preprocessor.cuda_image_array[i][0]\n",
    "    kernel_shape = net.conv1.kernel_size\n",
    "\n",
    "    data_0 = img[0]\n",
    "    data_1 = img[1]\n",
    "    data_2 = img[2]\n",
    "    print(data_1.shape)\n",
    "    x_enc_0, windows_nb_0 = ts.im2col_encoding(\n",
    "        context, data_0, kernel_shape[0],\n",
    "        kernel_shape[1], 1\n",
    "    )\n",
    "    x_enc_1, windows_nb_1 = ts.im2col_encoding(\n",
    "        context, data_1, kernel_shape[0],\n",
    "        kernel_shape[1], 1\n",
    "    )\n",
    "    x_enc_2, windows_nb_2 = ts.im2col_encoding(\n",
    "        context, data_2, kernel_shape[0],\n",
    "        kernel_shape[1], 1\n",
    "    )\n",
    "\n",
    "\n",
    "    x_enc_1_0, windows_nb_1_0 = ts.im2col_encoding(\n",
    "        context, data_0, 5,\n",
    "        5, 1\n",
    "    )\n",
    "    x_enc_1_1, windows_nb_1_1 = ts.im2col_encoding(\n",
    "        context, data_1, 5,\n",
    "       5, 1\n",
    "    )\n",
    "    x_enc_1_2, windows_nb_1_2 = ts.im2col_encoding(\n",
    "        context, data_2, 5,\n",
    "        5, 1\n",
    "    )\n",
    "    x_enc = (x_enc_0, x_enc_1, x_enc_2,   x_enc_1_0, x_enc_1_1 ,x_enc_1_2)\n",
    "    enc_output = enc_net(x_enc, windows_nb_1, windows_nb_1_2)\n",
    "    print(enc_output.decrypt())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
